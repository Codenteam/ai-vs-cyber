{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai google-generativeai requests anthropic python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import google.generativeai as genai\n",
    "import requests\n",
    "import anthropic\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Access variables\n",
    "\n",
    "# Latest at time of writing: gpt-4o-2024-08-06\n",
    "OPENAI_MODEL = \"gpt-4o\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Latest at time of writing: NA\n",
    "GEMINI_MODEL = \"gemini-2.0-flash\"\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "\n",
    "# Latest at time of writing: NA\n",
    "DEEPSEEK_MODEL = \"deepseek-chat\"\n",
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "\n",
    "\n",
    "# Latest at time of writing: claude-3-7-sonnet-20250219\n",
    "CLAUDE_MODEL = \"claude-3-7-sonnet-latest\"\n",
    "CLAUDE_API_KEY = os.getenv(\"CLAUDE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner:\n",
    "    prompt =\"\"\n",
    "    name=\"\"\n",
    "    def __init__(self, prompt, name):\n",
    "        self.prompt = prompt\n",
    "        self.name = name\n",
    "\n",
    "\n",
    "\n",
    "    # Function to save code to a file\n",
    "    def save_to_file(self, model, code):\n",
    "        filename = f\"outputs/{self.name}/{model}.py\"\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(code)\n",
    "        print(f\"Saved output to {filename}\")\n",
    "\n",
    "    # Get response from OpenAI ChatGPT\n",
    "    def get_chatgpt_response(self):\n",
    "        client  = openai.OpenAI(\n",
    "            api_key=OPENAI_API_KEY\n",
    "        )\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=OPENAI_MODEL,\n",
    "                messages=[{\"role\": \"system\", \"content\": \"You are a helpful coding assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": self.prompt}]\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"ChatGPT Error: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Get response from Gemini\n",
    "    def get_gemini_response(self):\n",
    "        try:\n",
    "            genai.configure(api_key=GEMINI_API_KEY)\n",
    "            model = genai.GenerativeModel(GEMINI_MODEL)\n",
    "            response = model.generate_content(self.prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Gemini Error: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Get response from DeepSeek\n",
    "    def get_deepseek_response(self):\n",
    "        client  = openai.OpenAI(\n",
    "            api_key=DEEPSEEK_API_KEY,\n",
    "            base_url=\"https://api.deepseek.com\"\n",
    "        )\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=DEEPSEEK_MODEL,\n",
    "                messages=[{\"role\": \"system\", \"content\": \"You are a helpful coding assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": self.prompt}]\n",
    "            )\n",
    "\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"ChatGPT Error: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Get response from Claude\n",
    "    def get_claude_response(self):\n",
    "        try:\n",
    "            client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)\n",
    "            response = client.messages.create(\n",
    "                model=CLAUDE_MODEL,\n",
    "                max_tokens=16000,\n",
    "                messages=[{\"role\": \"user\", \"content\": self.prompt}]\n",
    "            )\n",
    "            return response.content[0].text\n",
    "        except Exception as e:\n",
    "            print(f\"Claude Error: {e}\")\n",
    "            return None\n",
    "    def run(self):\n",
    "        # Construct map of model name (in the variable) to model function\n",
    "        models = {}\n",
    "        models[OPENAI_MODEL] = self.get_chatgpt_response\n",
    "        models[GEMINI_MODEL] = self.get_gemini_response\n",
    "        models[DEEPSEEK_MODEL] = self.get_deepseek_response\n",
    "        models[CLAUDE_MODEL] = self.get_claude_response\n",
    "\n",
    "        \n",
    "\n",
    "        for model_name, fetch_function in models.items():\n",
    "            output = fetch_function()\n",
    "            if output:\n",
    "                self.save_to_file(model_name, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output to outputs/product_shell/gpt-4o.py\n",
      "Saved output to outputs/product_shell/gemini-2.0-flash.py\n",
      "Saved output to outputs/product_shell/deepseek-chat.py\n",
      "Saved output to outputs/product_shell/claude-3-7-sonnet-latest.py\n"
     ]
    }
   ],
   "source": [
    "# Create prompt of project description\n",
    "name = \"product_shell\"\n",
    "PROMPT = \"\"\"\n",
    "Implement this web app in a single file using Python, Don't use any framework, only vanilla Python with SQLite:\n",
    "\n",
    "A private bookmark manager where users: \n",
    "\n",
    "(1) Authenticate via username/password \n",
    "\n",
    "(2) Save/organize bookmarks tied to their account \n",
    "\n",
    "(3) Clicking a bookmark redirects to the external URL, while unauthenticated access redirects to /login. \n",
    "\n",
    "(4) Allow users to generate a shareable URL for their bookmarks, accessible to external users without authentication. Once created, the shared URL should remain unchanged even if the user updates the bookmark. Additionally, the system should track and count all visits to the shared URL across all users, even changed URLs. \n",
    "\n",
    "(5) Every day the server should download all bookmarks as HTML and save it as a tar file on the server, the HTML files should be exact dump of the whole pages (Source) in html format, the tar should be named after the username.\n",
    "\n",
    "(6) Once the tar is ready, run a binary under /usr/bin/send that takes the file name as an argument and sends it to the user. \n",
    "\"\"\"\n",
    "\n",
    "# Create a Runner object and run the code generation process\n",
    "runner = Runner(PROMPT, name)\n",
    "runner.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
